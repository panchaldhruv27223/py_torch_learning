{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37ce301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc0db06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f46ba65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(a), torch.is_tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98f8b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_29068\\214256462.py:1: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  a.storage()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 2\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abfaac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_storage(a.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0980146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_complex(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6750bbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.+2.j, 3.+1.j])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([1 + 2j, 3 + 1j])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b247e3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 3.]), tensor([1.-2.j, 3.-1.j]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_real = b.real\n",
    "b_complex = b.conj()\n",
    "b_real, b_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d96b9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.-2.j, 3.-1.j])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.conj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770a6603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_complex_part = b.imag\n",
    "b_complex_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "915fb4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 3.]), tensor([2., 1.]), tensor([1.-2.j, 3.-1.j]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_real , b_complex_part, b_complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "112e7825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.+2.j, 3.+1.j])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "284ac248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False, True, False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_complex(b), torch.is_complex(b_real), torch.is_complex(b_complex), torch.is_complex(b_complex_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "524ecf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.tensor([1,2], dtype=torch.int32)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "091826f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_floating_point(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d8b15f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 3.]), True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_real, torch.is_floating_point(b_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0f26ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2], dtype=torch.int32), False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, torch.is_floating_point(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28de6414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero = torch.zeros(2,3)\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef70bd5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_nonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzero\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mis_nonzero(b_real)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "torch.is_nonzero(zero), torch.is_nonzero(b_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae67d504",
   "metadata": {},
   "source": [
    "torch.is_nonzero(torch.tensor([1, 2]))  # âŒ RuntimeError: more than one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0260b15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_nonzero(torch.tensor(0)),  torch.is_nonzero(torch.tensor(5)), torch.is_nonzero(torch.tensor(00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1adc0754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_nonzero(torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82764b3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_nonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "torch.is_nonzero(torch.tensor([0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf83566",
   "metadata": {},
   "source": [
    "âš ï¸ Only works on scalar tensors. Throws error if tensor has more than one element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a648142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the default floating-point type used in tensor creation when not explicitly set.\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81f5aa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "368123e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([1,2])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d563115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, torch.int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype,y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b701f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0], dtype=torch.float32)\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1ab6e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Sets the default floating-point type used in tensor creation when not explicitly set.\n",
    "\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "x = torch.tensor([1.0])\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8fb11e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84122c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7b479e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhruv\\Python_Envs\\dl_env\\lib\\site-packages\\torch\\__init__.py:1144: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\tensor\\python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2]), torch.int64, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)## used for cpu\n",
    "\n",
    "a = torch.tensor([1,2])\n",
    "a, a.dtype, a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f840650b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2.]), torch.float32, 1, device(type='cpu'), torch.Size([2]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.0,2])\n",
    "a, a.dtype, a.ndim, a.device, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f6986c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_default_tensor_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m## used for GPU\u001b[39;00m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.0\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m      3\u001b[0m a, a\u001b[38;5;241m.\u001b[39mdtype, a\u001b[38;5;241m.\u001b[39mndim, a\u001b[38;5;241m.\u001b[39mdevice, a\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\dhruv\\Python_Envs\\dl_env\\lib\\site-packages\\torch\\__init__.py:1144\u001b[0m, in \u001b[0;36mset_default_tensor_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1143\u001b[0m     t \u001b[38;5;241m=\u001b[39m _import_dotted_name(t)\n\u001b[1;32m-> 1144\u001b[0m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_default_tensor_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: type torch.cuda.FloatTensor not available. Torch not compiled with CUDA enabled."
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)## used for GPU\n",
    "a = torch.tensor([1.0,2])\n",
    "a, a.dtype, a.ndim, a.device, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ddaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "x = torch.tensor([1.0])  # created directly on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98984e25",
   "metadata": {},
   "source": [
    "ðŸ“Š Tensor Metadata & Debuggingm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f644e473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91f70e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2]), torch.int64, torch.Size([2]), 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a.dtype, a.shape, a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3dcaf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2190,  0.1221, -0.5958,  0.3178],\n",
       "        [-0.6745, -0.1970,  0.7593,  1.4676],\n",
       "        [ 0.3012, -0.7419, -0.2515,  0.5216]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a15eea69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd5aef38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55e42981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.12])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lets set some printing options\n",
    "\n",
    "torch.set_printoptions(precision=2, sci_mode=False)\n",
    "\n",
    "x = torch.tensor([3.1244666])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "757ee3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.12446665763855"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27a3617e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.12])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c056dc9",
   "metadata": {},
   "source": [
    "Options include:\n",
    "\n",
    "precision: digits after the decimal\n",
    "\n",
    "sci_mode: enable/disable scientific notation\n",
    "\n",
    "threshold: total elements before summarizing\n",
    "\n",
    "linewidth: max characters per line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127fa967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12d0d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flusing \n",
    "# Why? CPUs are slow when working with very tiny floating-point values (like 1e-308). Flushing avoids that slowdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d33e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6bcc56d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d06334a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.01)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el1 = torch.tensor(1328763.e-8)\n",
    "el1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95bf07ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.01)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(False)\n",
    "el1 = torch.tensor(1328763.e-8)\n",
    "el1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f67becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"default\") ## to set back to normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23d0b6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0133)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(False)\n",
    "el1 = torch.tensor(1328763.e-8)\n",
    "el1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e019bbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0133)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_flush_denormal(True)\n",
    "\n",
    "el1 = torch.tensor(1328763.e-8)\n",
    "el1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23a8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24dce63f",
   "metadata": {},
   "source": [
    "# Creation Ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd9d9483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor(data)\n",
    "# Creates a new tensor by copying the data.\n",
    "\n",
    "# No autograd history by default â†’ a leaf tensor.\n",
    "\n",
    "# Preserves dtype if given, or infers it from the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e2f9de64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, device(type='cpu'))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2])\n",
    "a.dtype, a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3ffa2ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float64, device(type='cpu'))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2], dtype=torch.float64)\n",
    "a.dtype, a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "56ae317a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… Use when: converting Python lists to PyTorch tensors.\n",
    "\n",
    "# ðŸ§  Hidden Tip: Avoid wrapping a tensor again:\n",
    "# torch.tensor(torch.tensor([1])) â†’ BAD (copies data again!)\n",
    "\n",
    "b = a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aaa5d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e460f74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "71fdec79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "08057367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## that why clone\n",
    "\n",
    "c = a.clone()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "96101943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2.], dtype=torch.float64), tensor([0., 2.], dtype=torch.float64))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0] = 1\n",
    "c, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e4246b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], dtype=torch.float64, requires_grad=True),\n",
       " tensor([1., 2., 3.], dtype=torch.float64))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float64,requires_grad=True)\n",
    "\n",
    "b = a.detach()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cdc09434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 2., 3.], dtype=torch.float64),\n",
       " tensor([0., 2., 3.], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0] = 0\n",
    "b,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e36cfee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  2.,  3.], dtype=torch.float64),\n",
       " tensor([0., 2., 3.], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.clone().detach()\n",
    "c[0] = 10\n",
    "c,a,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "190222ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Using clone()\n",
    "\n",
    "# Creates a deep copy of the tensor with its own memory.\n",
    "\n",
    "# Changes to the copied tensor do not affect the original.\n",
    "\n",
    "# Keeps the computation graph intact (useful when gradients are tracked).\n",
    "\n",
    "# 2. Using detach()\n",
    "\n",
    "# Creates a tensor that shares data with the original but is detached from the computation graph.\n",
    "\n",
    "# Useful when you want a tensor copy for inference or analysis without tracking gradients.\n",
    "\n",
    "# Changes to the detached tensor affect the original data since they share storage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef0ad79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "arr = np.array([1,2])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c39b6e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.as_tensor(arr)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f795120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back = torch.asarray(arr)\n",
    "back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ad29f059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back = torch.asarray(t)\n",
    "back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b4270a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse Tensor Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f8b823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse tensors save memory for data with lots of zeros. PyTorch supports multiple formats:\n",
    "\n",
    "# ðŸ§µ sparse_coo_tensor(indices, values, size)\n",
    "# COO = Coordinate format. Most flexible and commonly used sparse format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b0a3ea7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 1],\n",
       "                       [2, 0]]),\n",
       "       values=tensor([3, 4]),\n",
       "       size=(2, 3), nnz=2, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i  = torch.tensor([[0,1], [2,0]])\n",
    "v = torch.tensor([3,4])\n",
    "\n",
    "sparse = torch.sparse_coo_tensor(i,v,(2,3))\n",
    "sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663fb1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b830663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cc9bcc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,4])\n",
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10390243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "58c04856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = torch.ones(3,4)\n",
    "zero = torch.zeros(4,5)\n",
    "one, zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8224bf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([4, 5]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one.shape, zero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7c43b5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3],\n",
       "        [3, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "of3 = torch.full((4,5), 3)\n",
    "of3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cab8fb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,4)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4bdc8963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## i want to create same tensor like a \n",
    "\n",
    "b = torch.zeros_like(a)\n",
    "c = torch.ones_like(a)\n",
    "b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "470e5414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([3, 4]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "85127a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.empty(2,4)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b6a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb233c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.arange(2, 5, 10)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "35211f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 2.1000, 2.2000, 2.3000, 2.4000, 2.5000, 2.6000, 2.7000, 2.8000,\n",
       "        2.9000, 3.0000, 3.1000, 3.2000, 3.3000, 3.4000, 3.5000, 3.6000, 3.7000,\n",
       "        3.8000, 3.9000, 4.0000, 4.1000, 4.2000, 4.3000, 4.4000, 4.5000, 4.6000,\n",
       "        4.7000, 4.8000, 4.9000])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.arange(2, 5, 0.10)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "351145a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bcdc7ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_29068\\615080746.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  c = torch.range(1,3,1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.range(1,3,1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b906dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cf754923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## line space\n",
    "\n",
    "l1 = torch.linspace(2,10,5)\n",
    "l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0f91e1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), tensor([1.0000e+01, 3.1623e+05, 1.0000e+10]))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2  = torch.logspace(1,10,3 , base=10)\n",
    "l2.shape, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ed283841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), tensor([   2.0000,   45.2548, 1024.0000]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2  = torch.logspace(1,10,3 , base=2)\n",
    "l2.shape, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d9615a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), tensor([1., 1., 1.]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2  = torch.logspace(1,10,3 , base=1)\n",
    "l2.shape, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6d5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "23b7ac68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4]),\n",
       " tensor([[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.eye(4)\n",
    "i.shape, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "951808e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 6]),\n",
       " tensor([[1., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.eye(4,6)\n",
    "h.shape, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc51e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34cd0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 3, 1, 0])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## permutation \n",
    "\n",
    "\n",
    "torch.randperm(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ab38ed0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randperm(): argument 'n' (position 1) must be int, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## permutation \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandperm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: randperm(): argument 'n' (position 1) must be int, not tuple"
     ]
    }
   ],
   "source": [
    "## permutation \n",
    "\n",
    "\n",
    "torch.randperm((5,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "439a70e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 8, 3, 4, 0, 1, 2, 7, 6, 9])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(10)\n",
    "\n",
    "# randperm(n)\n",
    "# Random permutation of integers [0, n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499522f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00832b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6e3da0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0,2.0,3.0])\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "16b728e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], size=(3,), dtype=torch.qint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=0)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.quantize_per_tensor(x, scale=0.1,zero_point=0, dtype=torch.qint8)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6fed0ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq = q.dequantize()\n",
    "dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0825f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c29ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "61a2ecca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.+3.j, 2.+4.j])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## lets make complex tensor \n",
    "\n",
    "c = torch.complex(torch.tensor([1.,2]), torch.tensor([3.,4]))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "eed465bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in complex we have to pass both term real and complex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b85ff615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”® polar(abs, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "94a51403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.3711e-08+1.j])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "torch.polar(torch.tensor([1.0]), torch.tensor([math.pi/2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76362554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "141517dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 2.0000],\n",
       "        [0.0000, 2.1250, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = torch.empty(2,4)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "af4123d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7298,  1.0862,  0.1710, -0.5972],\n",
       "        [-0.1941, -0.9330,  0.8638,  0.5396],\n",
       "        [-0.1360, -1.2374,  0.6117,  0.6956]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.empty(3,4).normal_()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3fbca8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d4473a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8e0e1a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(4) @ torch.eye(4)  #### identity multiplicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c46969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "01a0b670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### \n",
    "x = torch.arange(9).reshape(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2700961d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3, 6],\n",
       "        [1, 4, 7],\n",
       "        [2, 5, 8]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.as_strided(x,(3,3),(1,3))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2f39e0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 3],\n",
       "        [1, 4]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.as_strided(x,(2,2),(1,3))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfeb522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fce29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6e101b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## low Memory grid creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8de77acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "         [-0.5000, -0.5000, -0.5000, -0.5000, -0.5000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.5000,  0.5000,  0.5000,  0.5000,  0.5000],\n",
       "         [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000]]),\n",
       " tensor([[-1.0000, -0.5000,  0.0000,  0.5000,  1.0000],\n",
       "         [-1.0000, -0.5000,  0.0000,  0.5000,  1.0000],\n",
       "         [-1.0000, -0.5000,  0.0000,  0.5000,  1.0000],\n",
       "         [-1.0000, -0.5000,  0.0000,  0.5000,  1.0000],\n",
       "         [-1.0000, -0.5000,  0.0000,  0.5000,  1.0000]]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.linspace(-1,1,5)\n",
    "y = torch.linspace(-1,1,5)\n",
    "\n",
    "grid_x, grid_y = torch.meshgrid(x, y, indexing=\"ij\")\n",
    "grid_x, grid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "984f0d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([5, 5]))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_x.shape, grid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e6e65d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24e36a4a790>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "73b14462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 4, 3, 0, 1])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices  = torch.randperm(5)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d304842a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1],\n",
       "          [ 2,  3]],\n",
       "\n",
       "         [[ 4,  5],\n",
       "          [ 6,  7]]],\n",
       "\n",
       "\n",
       "        [[[ 8,  9],\n",
       "          [10, 11]],\n",
       "\n",
       "         [[12, 13],\n",
       "          [14, 15]]]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(16).reshape(2,2,2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "acb7bfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[inf, inf, inf, inf, inf],\n",
       "        [inf, inf, inf, inf, inf],\n",
       "        [inf, inf, inf, inf, inf],\n",
       "        [inf, inf, inf, inf, inf],\n",
       "        [inf, inf, inf, inf, inf]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full((5,5), float(\"inf\"))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "940d3b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf],\n",
       "        [-inf, -inf, -inf, -inf, -inf]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full((5,5), float(\"-inf\"))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "00da599b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 1])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor([0,2,1])\n",
    "\n",
    "labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "55211695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = torch.nn.functional.one_hot(labels, num_classes=3)\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46376172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a7a54b4",
   "metadata": {},
   "source": [
    "# Indexing, Slicing, Joining, Mutating Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "25cdd58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.+2.j, 3.+4.j]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1+2j, 3+4j]], dtype= torch.complex64)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e706f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.-2.j],\n",
      "        [3.-4.j]])\n"
     ]
    }
   ],
   "source": [
    "print(x.adjoint()) # # Conjugate + transpose (for matrices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "592f1d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "df50ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]),\n",
       " tensor([[1.-2.j],\n",
       "         [3.-4.j]]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.adjoint()\n",
    "y.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d2eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8ecb24fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 0.]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[0,1],[2,0.0]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fa0b2617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argwhere(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "acb282fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.argwhere(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "56132483",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indices of non zero elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "995a1dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2]]), tensor([[3, 4]]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2]])\n",
    "b = torch.tensor([[3,4]])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bf64281b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a,b), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ae44900f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((a,b), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "eb6ee53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2]), torch.Size([1, 2]))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "00b7c1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.+2.j, 3.+4.j])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1+2j, 3+4j])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "706c4fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.-2.j, 3.-4.j])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.conj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "25cb891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## concate, concatenate, cat all are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ee62e758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b7bffd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1]), tensor([2, 3]), tensor([4, 5]), tensor([6, 7]))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(x,4) # Attempts to split a tensor into the specified number of chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f2401e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([4, 5, 6, 7]))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1f9793d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2345,  0.2303, -1.1229, -0.1863],\n",
       "        [ 2.2082, -0.6380,  0.4617,  0.2674],\n",
       "        [ 0.5349,  0.8094,  1.1103, -1.6898]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.randn(3,4)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2574cffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2345,  0.2303, -1.1229, -0.1863],\n",
       "         [ 2.2082, -0.6380,  0.4617,  0.2674]]),\n",
       " tensor([[ 0.5349,  0.8094,  1.1103, -1.6898]]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(arr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "33a46260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2345,  0.2303],\n",
       "         [ 2.2082, -0.6380],\n",
       "         [ 0.5349,  0.8094]]),\n",
       " tensor([[-1.1229, -0.1863],\n",
       "         [ 0.4617,  0.2674],\n",
       "         [ 1.1103, -1.6898]]))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(arr, 2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0c4f0fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1109,  0.0915, -2.3169, -0.2168],\n",
       "         [-1.3847, -0.8712, -0.2234,  1.7174],\n",
       "         [-0.4880,  1.1914, -0.8140, -0.7360]],\n",
       "\n",
       "        [[-0.8371, -0.9224,  1.8113,  0.1606],\n",
       "         [-0.0978,  1.8446, -1.1845,  1.3835],\n",
       "         [-1.2024,  0.7078, -1.0759,  0.5357]]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.randn(2,3,4)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6a5790e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.1109],\n",
       "          [-1.3847],\n",
       "          [-0.4880]],\n",
       " \n",
       "         [[-0.8371],\n",
       "          [-0.0978],\n",
       "          [-1.2024]]]),\n",
       " tensor([[[ 0.0915],\n",
       "          [-0.8712],\n",
       "          [ 1.1914]],\n",
       " \n",
       "         [[-0.9224],\n",
       "          [ 1.8446],\n",
       "          [ 0.7078]]]),\n",
       " tensor([[[-2.3169],\n",
       "          [-0.2234],\n",
       "          [-0.8140]],\n",
       " \n",
       "         [[ 1.8113],\n",
       "          [-1.1845],\n",
       "          [-1.0759]]]),\n",
       " tensor([[[-0.2168],\n",
       "          [ 1.7174],\n",
       "          [-0.7360]],\n",
       " \n",
       "         [[ 0.1606],\n",
       "          [ 1.3835],\n",
       "          [ 0.5357]]]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(arr, 4, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ec577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.1109,  0.0915, -2.3169, -0.2168],\n",
       "          [-1.3847, -0.8712, -0.2234,  1.7174],\n",
       "          [-0.4880,  1.1914, -0.8140, -0.7360]]]),\n",
       " tensor([[[-0.8371, -0.9224,  1.8113,  0.1606],\n",
       "          [-0.0978,  1.8446, -1.1845,  1.3835],\n",
       "          [-1.2024,  0.7078, -1.0759,  0.5357]]]))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(arr, 4, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "eb66fbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "67bb9444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[-1.1109,  0.0915, -2.3169, -0.2168]],\n",
       "  \n",
       "          [[-0.8371, -0.9224,  1.8113,  0.1606]]]),\n",
       "  tensor([[[-1.3847, -0.8712, -0.2234,  1.7174]],\n",
       "  \n",
       "          [[-0.0978,  1.8446, -1.1845,  1.3835]]]),\n",
       "  tensor([[[-0.4880,  1.1914, -0.8140, -0.7360]],\n",
       "  \n",
       "          [[-1.2024,  0.7078, -1.0759,  0.5357]]])),\n",
       " 3)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(arr, 4, dim=1) , len(torch.chunk(arr, 4, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d79dce20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1109,  0.0915, -2.3169, -0.2168],\n",
       "         [-1.3847, -0.8712, -0.2234,  1.7174],\n",
       "         [-0.4880,  1.1914, -0.8140, -0.7360]],\n",
       "\n",
       "        [[-0.8371, -0.9224,  1.8113,  0.1606],\n",
       "         [-0.0978,  1.8446, -1.1845,  1.3835],\n",
       "         [-1.2024,  0.7078, -1.0759,  0.5357]]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e32f2ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[-1.1109],\n",
       "           [-1.3847],\n",
       "           [-0.4880]],\n",
       "  \n",
       "          [[-0.8371],\n",
       "           [-0.0978],\n",
       "           [-1.2024]]]),\n",
       "  tensor([[[ 0.0915],\n",
       "           [-0.8712],\n",
       "           [ 1.1914]],\n",
       "  \n",
       "          [[-0.9224],\n",
       "           [ 1.8446],\n",
       "           [ 0.7078]]]),\n",
       "  tensor([[[-2.3169],\n",
       "           [-0.2234],\n",
       "           [-0.8140]],\n",
       "  \n",
       "          [[ 1.8113],\n",
       "           [-1.1845],\n",
       "           [-1.0759]]]),\n",
       "  tensor([[[-0.2168],\n",
       "           [ 1.7174],\n",
       "           [-0.7360]],\n",
       "  \n",
       "          [[ 0.1606],\n",
       "           [ 1.3835],\n",
       "           [ 0.5357]]])),\n",
       " 4)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(arr, 4, dim=2) , len(torch.chunk(arr, 4, dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2cd14691",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dsplit, hsplit, vsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "d828c628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]],\n",
       "\n",
       "        [[18, 19, 20],\n",
       "         [21, 22, 23],\n",
       "         [24, 25, 26]]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(27).reshape(3,3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9f93254c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.dsplit requires a tensor with at least 3 dimension, but got a tensor with 2 dimensions!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[215], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdsplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torch.dsplit requires a tensor with at least 3 dimension, but got a tensor with 2 dimensions!"
     ]
    }
   ],
   "source": [
    "print(torch.dsplit(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6c4c7fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0],\n",
      "         [ 3],\n",
      "         [ 6]],\n",
      "\n",
      "        [[ 9],\n",
      "         [12],\n",
      "         [15]],\n",
      "\n",
      "        [[18],\n",
      "         [21],\n",
      "         [24]]]), tensor([[[ 1],\n",
      "         [ 4],\n",
      "         [ 7]],\n",
      "\n",
      "        [[10],\n",
      "         [13],\n",
      "         [16]],\n",
      "\n",
      "        [[19],\n",
      "         [22],\n",
      "         [25]]]), tensor([[[ 2],\n",
      "         [ 5],\n",
      "         [ 8]],\n",
      "\n",
      "        [[11],\n",
      "         [14],\n",
      "         [17]],\n",
      "\n",
      "        [[20],\n",
      "         [23],\n",
      "         [26]]]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.dsplit(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6ff6c8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0],\n",
       "          [ 3],\n",
       "          [ 6]],\n",
       " \n",
       "         [[ 9],\n",
       "          [12],\n",
       "          [15]],\n",
       " \n",
       "         [[18],\n",
       "          [21],\n",
       "          [24]]]),\n",
       " torch.Size([3, 3, 1]))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1,x2,x3  = torch.dsplit(x,3)\n",
    "x1, x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8e1d998e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1],\n",
       "          [ 4],\n",
       "          [ 7]],\n",
       " \n",
       "         [[10],\n",
       "          [13],\n",
       "          [16]],\n",
       " \n",
       "         [[19],\n",
       "          [22],\n",
       "          [25]]]),\n",
       " torch.Size([3, 3, 1]))"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2, x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0d45df63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2],\n",
       "          [ 5],\n",
       "          [ 8]],\n",
       " \n",
       "         [[11],\n",
       "          [14],\n",
       "          [17]],\n",
       " \n",
       "         [[20],\n",
       "          [23],\n",
       "          [26]]]),\n",
       " torch.Size([3, 3, 1]))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3, x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "35c0af5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8]],\n",
       "\n",
       "        [[ 9, 10, 11],\n",
       "         [12, 13, 14],\n",
       "         [15, 16, 17]],\n",
       "\n",
       "        [[18, 19, 20],\n",
       "         [21, 22, 23],\n",
       "         [24, 25, 26]]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f9c0d160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0,  1,  2]],\n",
      "\n",
      "        [[ 9, 10, 11]],\n",
      "\n",
      "        [[18, 19, 20]]]), tensor([[[ 3,  4,  5]],\n",
      "\n",
      "        [[12, 13, 14]],\n",
      "\n",
      "        [[21, 22, 23]]]), tensor([[[ 6,  7,  8]],\n",
      "\n",
      "        [[15, 16, 17]],\n",
      "\n",
      "        [[24, 25, 26]]]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.hsplit(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b3727928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]]), tensor([[[ 9, 10, 11],\n",
      "         [12, 13, 14],\n",
      "         [15, 16, 17]]]), tensor([[[18, 19, 20],\n",
      "         [21, 22, 23],\n",
      "         [24, 25, 26]]]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.vsplit(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e9463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "45f271f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([4, 5, 6]))"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([4,5,6])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "148c6b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.column_stack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "3fa4b405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.vstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ad6aa6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "4ae2441d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 4],\n",
       "         [2, 5],\n",
       "         [3, 6]]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "64addc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]]), tensor([[4, 5, 6]]))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3]])\n",
    "b = torch.tensor([[4,5,6]])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "25626a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.vstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "75ffb45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "27eedfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 4],\n",
       "         [2, 5],\n",
       "         [3, 6]]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "93b8a5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([1, 3]), torch.Size([1, 6]))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape, torch.hstack((a,b)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b3fdb43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 4],\n",
       "         [2, 5],\n",
       "         [3, 6]]])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c39211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c3157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47cd7a04",
   "metadata": {},
   "source": [
    "## gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "135c7893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [3, 4]]),\n",
       " tensor([[0, 1],\n",
       "         [1, 0]]))"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1,2],[3,4]])\n",
    "index = torch.tensor([[0,1],[1,0]])\n",
    "t, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c99337f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [4, 3]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(t, 1, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "887eab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: The source tensor from which values are gathered.\n",
    "\n",
    "# dim: The dimension along which to gather values.\n",
    "\n",
    "# index: A tensor of indices specifying which elements to select from input along the given dimension.\n",
    "\n",
    "# Output:\n",
    "# The output tensor has the same shape as the index tensor. Each element in the output is taken from the input tensor at the position specified by the corresponding index along the dimension dim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "41ea6f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [3, 2]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(t, 0, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "1d79bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. index_select / masked_select ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f378c02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[1,2],[3,4]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2d7a71ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3]])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## select some index \n",
    "\n",
    "torch.index_select(t,1,torch.tensor(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "91405780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1],\n",
       "         [3]]),\n",
       " tensor([[1, 2],\n",
       "         [3, 4]]))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## select some index \n",
    "\n",
    "## tensor, dimension, index tensor \n",
    "torch.index_select(t,1, torch.tensor([0]) ), torch.index_select(t,1, torch.tensor([0,1]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "46557dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(t, t>2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c3b138fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.4665e-01, -1.9733e-01, -1.0546e+00,  1.2780e+00,  1.4534e-01],\n",
       "          [ 2.3105e-01,  8.6540e-03, -1.4229e-01,  5.7501e-01, -6.4172e-01],\n",
       "          [-2.2064e+00, -7.5080e-01,  2.8140e+00,  3.5979e-01, -8.9808e-02]],\n",
       "\n",
       "         [[ 4.5844e-01,  5.3619e-01,  5.2462e-01,  1.1412e+00,  5.1644e-02],\n",
       "          [ 7.2811e-01, -7.1064e-01, -6.0207e-01,  9.6045e-01, -1.7223e+00],\n",
       "          [-8.2777e-01,  1.3347e+00,  4.8354e-01, -1.9756e-01,  1.2683e+00]],\n",
       "\n",
       "         [[ 1.2243e+00,  9.8117e-02,  6.4076e-01,  5.8325e-01,  1.0669e+00],\n",
       "          [-4.5015e-01, -6.7875e-01,  5.7432e-01,  1.8775e-01, -3.5762e-01],\n",
       "          [ 2.6491e-01,  1.2732e+00, -1.3109e-03, -3.0360e-01, -9.8644e-01]],\n",
       "\n",
       "         [[ 1.2330e-01,  3.4987e-01,  6.1728e-01,  7.2618e-01,  9.1152e-02],\n",
       "          [-3.8907e-01,  5.2792e-01,  1.0311e+00, -7.0477e-01,  1.0131e+00],\n",
       "          [-3.3082e-01,  1.0950e+00,  3.3989e-01,  7.1997e-01,  4.1141e-01]]],\n",
       "\n",
       "\n",
       "        [[[-5.7332e-01,  5.0686e-01, -4.7521e-01, -4.9203e-01, -1.3603e-01],\n",
       "          [ 1.6354e+00,  6.5474e-01,  5.7600e-01, -3.6091e-01, -6.0590e-02],\n",
       "          [ 7.3255e-02,  8.1865e-01, -3.7534e-01,  1.0331e+00, -6.8665e-01]],\n",
       "\n",
       "         [[ 6.3681e-01,  2.1755e-01, -4.6655e-02, -1.4335e+00, -5.6653e-01],\n",
       "          [ 2.6948e-01, -2.1038e-01, -7.3280e-01,  1.0430e-01,  1.0414e+00],\n",
       "          [-3.9973e-01, -2.2933e+00,  4.9756e-01, -2.4801e+00, -4.1754e-01]],\n",
       "\n",
       "         [[-1.1955e+00,  8.1234e-01, -3.0628e-01, -3.3016e-01, -9.8080e-01],\n",
       "          [ 1.9473e-01,  2.8683e-01, -7.3084e-01,  1.7482e-01, -1.0939e+00],\n",
       "          [ 9.6334e-01, -3.0953e-01,  5.7120e-01,  1.1179e+00, -9.5632e-01]],\n",
       "\n",
       "         [[-1.2476e+00, -7.4994e-01, -5.9219e-01,  1.7744e+00, -9.2155e-01],\n",
       "          [ 9.6245e-01, -3.3702e-01, -4.3871e-02,  2.3681e-01, -7.0607e-01],\n",
       "          [-7.1691e-01,  5.2606e-01,  2.1120e+00, -5.2076e-01, -9.3201e-01]]]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = torch.randn(2,4,3,5)\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5bcef7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2780, 2.8140, 1.1412, 1.3347, 1.2683, 1.2243, 1.0669, 1.2732, 1.0311,\n",
       "        1.0131, 1.0950, 1.6354, 1.0331, 1.0414, 1.1179, 1.7744, 2.1120])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(ar, ar > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a1d8be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef6012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2566b8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.4665e-01, -1.9733e-01, -1.0546e+00,  1.2780e+00,  1.4534e-01],\n",
       "          [ 2.3105e-01,  8.6540e-03, -1.4229e-01,  5.7501e-01, -6.4172e-01],\n",
       "          [-2.2064e+00, -7.5080e-01,  2.8140e+00,  3.5979e-01, -8.9808e-02]],\n",
       "\n",
       "         [[ 4.5844e-01,  5.3619e-01,  5.2462e-01,  1.1412e+00,  5.1644e-02],\n",
       "          [ 7.2811e-01, -7.1064e-01, -6.0207e-01,  9.6045e-01, -1.7223e+00],\n",
       "          [-8.2777e-01,  1.3347e+00,  4.8354e-01, -1.9756e-01,  1.2683e+00]],\n",
       "\n",
       "         [[ 1.2243e+00,  9.8117e-02,  6.4076e-01,  5.8325e-01,  1.0669e+00],\n",
       "          [-4.5015e-01, -6.7875e-01,  5.7432e-01,  1.8775e-01, -3.5762e-01],\n",
       "          [ 2.6491e-01,  1.2732e+00, -1.3109e-03, -3.0360e-01, -9.8644e-01]],\n",
       "\n",
       "         [[ 1.2330e-01,  3.4987e-01,  6.1728e-01,  7.2618e-01,  9.1152e-02],\n",
       "          [-3.8907e-01,  5.2792e-01,  1.0311e+00, -7.0477e-01,  1.0131e+00],\n",
       "          [-3.3082e-01,  1.0950e+00,  3.3989e-01,  7.1997e-01,  4.1141e-01]]],\n",
       "\n",
       "\n",
       "        [[[-5.7332e-01,  5.0686e-01, -4.7521e-01, -4.9203e-01, -1.3603e-01],\n",
       "          [ 1.6354e+00,  6.5474e-01,  5.7600e-01, -3.6091e-01, -6.0590e-02],\n",
       "          [ 7.3255e-02,  8.1865e-01, -3.7534e-01,  1.0331e+00, -6.8665e-01]],\n",
       "\n",
       "         [[ 6.3681e-01,  2.1755e-01, -4.6655e-02, -1.4335e+00, -5.6653e-01],\n",
       "          [ 2.6948e-01, -2.1038e-01, -7.3280e-01,  1.0430e-01,  1.0414e+00],\n",
       "          [-3.9973e-01, -2.2933e+00,  4.9756e-01, -2.4801e+00, -4.1754e-01]],\n",
       "\n",
       "         [[-1.1955e+00,  8.1234e-01, -3.0628e-01, -3.3016e-01, -9.8080e-01],\n",
       "          [ 1.9473e-01,  2.8683e-01, -7.3084e-01,  1.7482e-01, -1.0939e+00],\n",
       "          [ 9.6334e-01, -3.0953e-01,  5.7120e-01,  1.1179e+00, -9.5632e-01]],\n",
       "\n",
       "         [[-1.2476e+00, -7.4994e-01, -5.9219e-01,  1.7744e+00, -9.2155e-01],\n",
       "          [ 9.6245e-01, -3.3702e-01, -4.3871e-02,  2.3681e-01, -7.0607e-01],\n",
       "          [-7.1691e-01,  5.2606e-01,  2.1120e+00, -5.2076e-01, -9.3201e-01]]]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## move dimensions, axis\n",
    "\n",
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3b2090fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 5])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5a52311e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 5])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b6460cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5, 3])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.movedim(ar, -1, -2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "df2d5913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 5])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.movedim(ar, 0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8e8d7c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2, 5])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.movedim(ar, 0, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "4eb1a9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 3, 5]), torch.Size([4, 2, 3, 5]))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.shape, torch.moveaxis(ar, 0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4e493dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 5])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "31cad90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 4])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.moveaxis(ar, 1,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc962e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.moveaxis(ar, 0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1822ade6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 3, 5]), torch.Size([4, 2, 3, 5]))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.shape, torch.moveaxis(ar, 0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ab7bdb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this move dim and move axis its just move the dim do not swap the dimensiton "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "aff3c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Creates a view (not a copy) of the original tensor t along dimension 0 (rows), starting at index 2 and selecting 4 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320130f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5dba6fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "becf25af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), tensor([2, 3, 4, 5]))"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape, torch.narrow(t, 0, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "b7925eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8719, -0.0271, -0.3532,  1.4639],\n",
       "         [ 0.1729,  1.0514,  0.0075, -0.0774],\n",
       "         [ 0.8351, -0.3157,  0.2691,  0.0854]]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = torch.randn(2,3,4)\n",
    "\n",
    "torch.narrow(ar, 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "620762f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.7189e-01, -2.7118e-02, -3.5325e-01,  1.4639e+00],\n",
       "         [ 1.7290e-01,  1.0514e+00,  7.4915e-03, -7.7365e-02],\n",
       "         [ 8.3509e-01, -3.1571e-01,  2.6911e-01,  8.5404e-02]],\n",
       "\n",
       "        [[-1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02],\n",
       "         [ 5.2394e-01, -2.6935e-01, -1.6191e+00,  1.2588e-03],\n",
       "         [ 1.1930e+00,  1.9373e+00,  7.2871e-01,  9.8089e-01]]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4fca6962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "cba8189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-8.7189e-01, -2.7118e-02, -3.5325e-01,  1.4639e+00],\n",
       "          [ 1.7290e-01,  1.0514e+00,  7.4915e-03, -7.7365e-02],\n",
       "          [ 8.3509e-01, -3.1571e-01,  2.6911e-01,  8.5404e-02]],\n",
       " \n",
       "         [[-1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02],\n",
       "          [ 5.2394e-01, -2.6935e-01, -1.6191e+00,  1.2588e-03],\n",
       "          [ 1.1930e+00,  1.9373e+00,  7.2871e-01,  9.8089e-01]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar, ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "fac158cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.7189e-01, -2.7118e-02, -3.5325e-01,  1.4639e+00],\n",
       "         [ 1.7290e-01,  1.0514e+00,  7.4915e-03, -7.7365e-02]],\n",
       "\n",
       "        [[-1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02],\n",
       "         [ 5.2394e-01, -2.6935e-01, -1.6191e+00,  1.2588e-03]]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(ar, 1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "996e8ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(ar, 1, 0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "10d8514c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(ar, 1, 0, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2049c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-8.7189e-01, -2.7118e-02, -3.5325e-01,  1.4639e+00],\n",
       "          [ 1.7290e-01,  1.0514e+00,  7.4915e-03, -7.7365e-02],\n",
       "          [ 8.3509e-01, -3.1571e-01,  2.6911e-01,  8.5404e-02]],\n",
       " \n",
       "         [[-1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02],\n",
       "          [ 5.2394e-01, -2.6935e-01, -1.6191e+00,  1.2588e-03],\n",
       "          [ 1.1930e+00,  1.9373e+00,  7.2871e-01,  9.8089e-01]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar, ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "6f7d443e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8719],\n",
       "          [ 0.1729],\n",
       "          [ 0.8351]],\n",
       " \n",
       "         [[-1.3793],\n",
       "          [ 0.5239],\n",
       "          [ 1.1930]]]),\n",
       " torch.Size([2, 3, 1]))"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(ar, 2, 0 ,1), torch.narrow(ar, 2, 0 ,1).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9a11c1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8719, -0.0271],\n",
       "          [ 0.1729,  1.0514],\n",
       "          [ 0.8351, -0.3157]],\n",
       " \n",
       "         [[-1.3793,  0.6258],\n",
       "          [ 0.5239, -0.2694],\n",
       "          [ 1.1930,  1.9373]]]),\n",
       " torch.Size([2, 3, 2]))"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(ar, 2, 0 ,2), torch.narrow(ar, 2, 0 ,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36b77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8719, -0.0271, -0.3532],\n",
       "          [ 0.1729,  1.0514,  0.0075],\n",
       "          [ 0.8351, -0.3157,  0.2691]],\n",
       " \n",
       "         [[-1.3793,  0.6258, -2.5850],\n",
       "          [ 0.5239, -0.2694, -1.6191],\n",
       "          [ 1.1930,  1.9373,  0.7287]]]),\n",
       " torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(ar, 2, 0 , 3), torch.narrow(ar, 2, 0 , 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7fec59d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-8.7189e-01, -2.7118e-02, -3.5325e-01,  1.4639e+00],\n",
       "          [ 1.7290e-01,  1.0514e+00,  7.4915e-03, -7.7365e-02],\n",
       "          [ 8.3509e-01, -3.1571e-01,  2.6911e-01,  8.5404e-02]],\n",
       " \n",
       "         [[-1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02],\n",
       "          [ 5.2394e-01, -2.6935e-01, -1.6191e+00,  1.2588e-03],\n",
       "          [ 1.1930e+00,  1.9373e+00,  7.2871e-01,  9.8089e-01]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.narrow(ar, 2, 0 , 4), torch.narrow(ar, 2, 0 , 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "cd767586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]),\n",
       " tensor([[[-8.7189e-01, -2.7118e-02, -3.5325e-01,  1.4639e+00],\n",
       "          [ 1.7290e-01,  1.0514e+00,  7.4915e-03, -7.7365e-02],\n",
       "          [ 8.3509e-01, -3.1571e-01,  2.6911e-01,  8.5404e-02]],\n",
       " \n",
       "         [[-1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02],\n",
       "          [ 5.2394e-01, -2.6935e-01, -1.6191e+00,  1.2588e-03],\n",
       "          [ 1.1930e+00,  1.9373e+00,  7.2871e-01,  9.8089e-01]]]))"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.shape, ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "52c6d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## it we want to save it some where and dont want to share the memory then we use narrow_copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "68c9fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "a7735725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.7189e-01, -2.7118e-02, -3.5325e-01,  1.4639e+00],\n",
       "         [ 1.7290e-01,  1.0514e+00,  7.4915e-03, -7.7365e-02],\n",
       "         [ 8.3509e-01, -3.1571e-01,  2.6911e-01,  8.5404e-02]],\n",
       "\n",
       "        [[-1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02],\n",
       "         [ 5.2394e-01, -2.6935e-01, -1.6191e+00,  1.2588e-03],\n",
       "         [ 1.1930e+00,  1.9373e+00,  7.2871e-01,  9.8089e-01]]])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1  = torch.narrow_copy(ar, -1, 0, ar.shape[-1])\n",
    "e1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd906183",
   "metadata": {},
   "source": [
    "Feature\ttorch.narrow() (View)\ttorch.narrow_copy() (Copy)\n",
    "\n",
    "Memory Sharing\tShares memory with original tensor\tCreates a new memory allocation\n",
    "\n",
    "In-Place Safety\tRisky (modifications affect original)\tSafe (independent of original)\n",
    "\n",
    "Performance\tFaster (no data duplication)\tSlower (data copied)\n",
    "\n",
    "Use Case\tEfficient data subset extraction\tIsolated operations on the subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e58988b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## non zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "710d7087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.7987,  0.9105, -0.0880,  0.3370],\n",
       "          [ 0.9733, -1.0151, -0.5419, -0.4410],\n",
       "          [ 0.4536,  1.2461, -2.3065, -1.2869]],\n",
       " \n",
       "         [[ 0.2137, -1.2351,  1.8592,  0.0561],\n",
       "          [-0.7647, -0.0553,  1.2049, -0.9825],\n",
       "          [ 0.3040,  0.9339, -1.9726, -1.4120]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(2,3,4)\n",
    "t, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "2c7263ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 2],\n",
       "        [0, 0, 3],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 1],\n",
       "        [0, 1, 2],\n",
       "        [0, 1, 3],\n",
       "        [0, 2, 0],\n",
       "        [0, 2, 1],\n",
       "        [0, 2, 2],\n",
       "        [0, 2, 3],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 1],\n",
       "        [1, 0, 2],\n",
       "        [1, 0, 3],\n",
       "        [1, 1, 0],\n",
       "        [1, 1, 1],\n",
       "        [1, 1, 2],\n",
       "        [1, 1, 3],\n",
       "        [1, 2, 0],\n",
       "        [1, 2, 1],\n",
       "        [1, 2, 2],\n",
       "        [1, 2, 3]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will return the index \n",
    "\n",
    "torch.nonzero(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d4604",
   "metadata": {},
   "source": [
    "### permute | transpose | swapaxes | swapdims.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d71b5e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9624, -0.1426,  0.1527, -0.0388],\n",
       "         [-0.2130, -0.5904,  0.4668,  0.3956],\n",
       "         [-0.3016, -1.4033, -1.3271, -0.9948]],\n",
       "\n",
       "        [[-0.4940,  1.1366, -0.4618,  1.4200],\n",
       "         [ 0.8211, -0.0675,  0.9491, -0.3983],\n",
       "         [ 0.6899, -1.3129,  0.0378, -1.1702]]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f6ccc0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.permute(2,0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "9960e76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "1cbb0fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.swapaxes(x, 2,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f9c9ce05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.swapdims(x, 2, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "21ea3726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "9696b4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "789a8613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.9624, -0.1426,  0.1527, -0.0388],\n",
       "          [-0.2130, -0.5904,  0.4668,  0.3956],\n",
       "          [-0.3016, -1.4033, -1.3271, -0.9948]],\n",
       " \n",
       "         [[-0.4940,  1.1366, -0.4618,  1.4200],\n",
       "          [ 0.8211, -0.0675,  0.9491, -0.3983],\n",
       "          [ 0.6899, -1.3129,  0.0378, -1.1702]]]),\n",
       " tensor([[[ 0.9624, -0.1426,  0.1527, -0.0388],\n",
       "          [-0.4940,  1.1366, -0.4618,  1.4200]],\n",
       " \n",
       "         [[-0.2130, -0.5904,  0.4668,  0.3956],\n",
       "          [ 0.8211, -0.0675,  0.9491, -0.3983]],\n",
       " \n",
       "         [[-0.3016, -1.4033, -1.3271, -0.9948],\n",
       "          [ 0.6899, -1.3129,  0.0378, -1.1702]]]))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x , x.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7228a207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "945c3965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9b4adcdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "925532ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "74cafb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[[[[1]]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "b32bc477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[1]]]]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "baccb59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "b981e60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y.squeeze()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "66a20fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "75aaeebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1]), torch.Size([1]))"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = z.unsqueeze(0)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "7cdec507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1]]), torch.Size([1, 1]))"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.unsqueeze(0), z.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b5314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "066ca2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.zeros(3,5, dtype=torch.float64)\n",
    "index = torch.tensor([[0,1,2],[2,0,4],[3,1,3]])\n",
    "src = torch.tensor([[1,2,3],[4,5,6],[7,8,9]], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "54f5c459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 0., 0.],\n",
       "        [5., 0., 4., 0., 6.],\n",
       "        [0., 8., 0., 9., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.scatter(t, 1, index, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b4cad633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an in-place method:\n",
    "# input.scatter_(dim, index, src, reduce=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "1d33fc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "cb9fed9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 5., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inplace methods\n",
    "t.scatter_(0, torch.tensor([[0,2]]), torch.tensor([[1, 5]], dtype=torch.float64))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "ea76c347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 5., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cfe3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "fff7e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. scatter_add_\n",
    "# Adds values from src to input at specified indices instead of overwriting.\n",
    "\n",
    "# Useful when multiple values map to the same index and you want to accumulate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "b7fa64f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.4372, -0.7067,  1.3422,  0.5235],\n",
       "         [-0.2640, -0.3286, -0.3712, -0.5473],\n",
       "         [ 1.3824, -0.7472, -2.5696,  0.1018]], dtype=torch.float64),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(3,4,  dtype=torch.float64)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "f14eaa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 5.],\n",
       "        [4., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.tensor([[0,2],[2,2]])\n",
    "src = torch.tensor([[3,5],[4,4]], dtype=torch.float64)\n",
    "\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "cefd17fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "8fca55bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.4372, -0.7067,  1.3422,  0.5235],\n",
       "         [-0.2640, -0.3286, -0.3712, -0.5473],\n",
       "         [ 5.3824,  8.2528, -2.5696,  0.1018]], dtype=torch.float64),\n",
       " tensor([[ 4.4372, -0.7067,  6.3422,  0.5235],\n",
       "         [-0.2640, -0.3286,  7.6288, -0.5473],\n",
       "         [ 1.3824, -0.7472, -2.5696,  0.1018]], dtype=torch.float64))"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.scatter_add(0, index, src), z.scatter_add(1, index, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b8748f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "dd39819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter with reduce argument (PyTorch 1.10+)\n",
    "# Supports reduction operations like 'add', 'multiply', 'mean', 'min', 'max' when multiple writes target the same index.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "31fce03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9]))"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(10)\n",
    "\n",
    "torch.split(t, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "3f82795a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7]), tensor([8, 9]))"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor_split(t, [3,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "3c54b285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([4, 5]), tensor([6, 7]), tensor([8, 9]))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor_split(t, [4,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c140ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "f401570e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([4, 5, 6]))"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## stack / unbind \n",
    "\n",
    "a = torch.tensor([1,2,3])\n",
    "b = torch.tensor([4,5,6])\n",
    "\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "01056c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "692c2d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "a289da88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.vstack((a,b))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "5c0deec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.unbind(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "e28e4e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([4, 5, 6]))"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "ed4c8bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "08a93116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 4]), tensor([2, 5]), tensor([3, 6]))"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unbind(c, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "3858c27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d6282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b755bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "2ab4ed50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 20],\n",
       "        [30, 40]])"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## take / take_along_dim \n",
    "\n",
    "t = torch.tensor([[10,20], [30,40]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "1b9c9ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "b2f37087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 30])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take(t, torch.tensor([0,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "db6cf00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 40])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take(t, torch.tensor([0,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017da8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "bbb25c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## \n",
    "indices = torch.tensor([[0,0],[1,0]])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "e87c0a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 10],\n",
       "        [40, 30]])"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.take_along_dim(t, indices, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c3975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e699f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ea2ac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "a78ffd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
      "        [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0,1,2])\n",
    "\n",
    "print(torch.tile(a, (2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "d5d3234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2]), torch.Size([3]))"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "946e0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dims (tuple): the number of repetitions per dimension.\n",
    "\n",
    "\n",
    "# tile(input, dims) -> Tensor\n",
    "\n",
    "# Constructs a tensor by repeating the elements of input.\n",
    "# The dims argument specifies the number of repetitions in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "8047ab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 0, 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([0,1,2,3])\n",
    "\n",
    "print(torch.tile(a, (1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b5573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bddd9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "3af50fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 6, 6]), tensor([4, 5, 1]))"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## unravel index \n",
    "\n",
    "indices = torch.tensor([22, 41, 37])\n",
    "shape = (7,6)\n",
    "\n",
    "torch.unravel_index(indices, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "e0f6f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the Mapping Works\n",
    "# For a 2D tensor with shape (rows, columns), the mapping is:\n",
    "\n",
    "# row = index // columns\n",
    "\n",
    "# column = index % columns\n",
    "\n",
    "# Apply to Each Index\n",
    "# 22:\n",
    "\n",
    "# row = 22 // 6 = 3\n",
    "\n",
    "# col = 22 % 6 = 4\n",
    "\n",
    "# â†’ (3, 4)\n",
    "\n",
    "# 41:\n",
    "\n",
    "# row = 41 // 6 = 6\n",
    "\n",
    "# col = 41 % 6 = 5\n",
    "\n",
    "# â†’ (6, 5)\n",
    "\n",
    "# 37:\n",
    "\n",
    "# row = 37 // 6 = 6\n",
    "\n",
    "# col = 37 % 6 = 1\n",
    "\n",
    "# â†’ (6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc257c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "787a205b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4]), tensor([9, 8, 7, 6]))"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## where \n",
    "\n",
    "x = torch.tensor([1,2,3,4])\n",
    "y = torch.tensor([9,8,7,6])\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a98aa04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 8, 3, 6])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = torch.tensor([True, False, True, False])\n",
    "\n",
    "torch.where(cond, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "8e100325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output element (from x if cond True else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "46c444cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.where(condition, x, y) returns a tensor where each element is selected from x if the corresponding element in condition is True, otherwise from y.\n",
    "\n",
    "# It works element-wise, meaning it checks each element of condition and picks from x or y accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d2186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
