{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question      answer\n",
       "0                   What is the capital of France?       Paris\n",
       "1                  What is the capital of Germany?      Berlin\n",
       "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
       "3  What is the largest planet in our solar system?     Jupiter\n",
       "4   What is the boiling point of water in Celsius?         100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"c:\\Users\\dhruv\\Downloads\\100_Unique_QA_Dataset.csv\")\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenizer \n",
    "def tokenizer(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"?\",\"\")\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    text = text.replace(\".\",\"\")\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'dhruv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"i am dhruv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'is', 'the', 'capital', 'of', 'france']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {\"<UNK>\":0}\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<UNK>': 0}\n"
     ]
    }
   ],
   "source": [
    "def build_vocab(row):\n",
    "    # print(row[\"question\"] ,\"|\", row[\"answer\"])\n",
    "    tokenized_question = tokenizer(row[\"question\"])\n",
    "    tokenized_answer = tokenizer(row[\"answer\"])\n",
    "\n",
    "    merged_tokens = tokenized_question + tokenized_answer\n",
    "\n",
    "    for tok in merged_tokens:\n",
    "        if tok not in vocab.keys():\n",
    "            vocab[tok] = len(vocab)\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "85    None\n",
       "86    None\n",
       "87    None\n",
       "88    None\n",
       "89    None\n",
       "Length: 90, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.apply(build_vocab, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'capital': 4, 'of': 5, 'france': 6, 'paris': 7, 'germany': 8, 'berlin': 9, 'who': 10, 'wrote': 11, 'to': 12, 'kill': 13, 'a': 14, 'mockingbird': 15, 'harper-lee': 16, 'largest': 17, 'planet': 18, 'in': 19, 'our': 20, 'solar': 21, 'system': 22, 'jupiter': 23, 'boiling': 24, 'point': 25, 'water': 26, 'celsius': 27, '100': 28, 'painted': 29, 'mona': 30, 'lisa': 31, 'leonardo-da-vinci': 32, 'square': 33, 'root': 34, '64': 35, '8': 36, 'chemical': 37, 'symbol': 38, 'for': 39, 'gold': 40, 'au': 41, 'which': 42, 'year': 43, 'did': 44, 'world': 45, 'war': 46, 'ii': 47, 'end': 48, '1945': 49, 'longest': 50, 'river': 51, 'nile': 52, 'japan': 53, 'tokyo': 54, 'developed': 55, 'theory': 56, 'relativity': 57, 'albert-einstein': 58, 'freezing': 59, 'fahrenheit': 60, '32': 61, 'known': 62, 'as': 63, 'red': 64, 'mars': 65, 'author': 66, '1984': 67, 'george-orwell': 68, 'currency': 69, 'united': 70, 'kingdom': 71, 'pound': 72, 'india': 73, 'delhi': 74, 'discovered': 75, 'gravity': 76, 'newton': 77, 'how': 78, 'many': 79, 'continents': 80, 'are': 81, 'there': 82, 'on': 83, 'earth': 84, '7': 85, 'gas': 86, 'do': 87, 'plants': 88, 'use': 89, 'photosynthesis': 90, 'co2': 91, 'smallest': 92, 'prime': 93, 'number': 94, '2': 95, 'invented': 96, 'telephone': 97, 'alexander-graham-bell': 98, 'australia': 99, 'canberra': 100, 'ocean': 101, 'pacific-ocean': 102, 'speed': 103, 'light': 104, 'vacuum': 105, '299,792,458m/s': 106, 'language': 107, 'spoken': 108, 'brazil': 109, 'portuguese': 110, 'penicillin': 111, 'alexander-fleming': 112, 'canada': 113, 'ottawa': 114, 'mammal': 115, 'whale': 116, 'element': 117, 'has': 118, 'atomic': 119, '1': 120, 'hydrogen': 121, 'tallest': 122, 'mountain': 123, 'everest': 124, 'city': 125, 'big': 126, 'apple': 127, 'newyork': 128, 'planets': 129, 'starry': 130, 'night': 131, 'vangogh': 132, 'formula': 133, 'h2o': 134, 'italy': 135, 'rome': 136, 'country': 137, 'famous': 138, 'sushi': 139, 'was': 140, 'first': 141, 'person': 142, 'step': 143, 'moon': 144, 'armstrong': 145, 'main': 146, 'ingredient': 147, 'guacamole': 148, 'avocado': 149, 'sides': 150, 'does': 151, 'hexagon': 152, 'have': 153, '6': 154, 'china': 155, 'yuan': 156, 'pride': 157, 'and': 158, 'prejudice': 159, 'jane-austen': 160, 'iron': 161, 'fe': 162, 'hardest': 163, 'natural': 164, 'substance': 165, 'diamond': 166, 'continent': 167, 'by': 168, 'area': 169, 'asia': 170, 'president': 171, 'states': 172, 'george-washington': 173, 'bird': 174, 'its': 175, 'ability': 176, 'mimic': 177, 'sounds': 178, 'parrot': 179, 'longest-running': 180, 'animated': 181, 'tv': 182, 'show': 183, 'simpsons': 184, 'vaticancity': 185, 'most': 186, 'moons': 187, 'saturn': 188, 'romeo': 189, 'juliet': 190, 'shakespeare': 191, 'earths': 192, 'atmosphere': 193, 'nitrogen': 194, 'bones': 195, 'adult': 196, 'human': 197, 'body': 198, '206': 199, 'metal': 200, 'liquid': 201, 'at': 202, 'room': 203, 'temperature': 204, 'mercury': 205, 'russia': 206, 'moscow': 207, 'electricity': 208, 'benjamin-franklin': 209, 'second-largest': 210, 'land': 211, 'color': 212, 'ripe': 213, 'banana': 214, 'yellow': 215, 'month': 216, '28': 217, 'days': 218, 'common': 219, 'february': 220, 'study': 221, 'living': 222, 'organisms': 223, 'called': 224, 'biology': 225, 'home': 226, 'great': 227, 'wall': 228, 'bees': 229, 'collect': 230, 'from': 231, 'flowers': 232, 'nectar': 233, 'opposite': 234, 'day': 235, 'south': 236, 'korea': 237, 'seoul': 238, 'bulb': 239, 'edison': 240, 'humans': 241, 'breathe': 242, 'survival': 243, 'oxygen': 244, '144': 245, '12': 246, 'pyramids': 247, 'giza': 248, 'egypt': 249, 'sea': 250, 'creature': 251, 'eight': 252, 'arms': 253, 'octopus': 254, 'holiday': 255, 'celebrated': 256, 'december': 257, '25': 258, 'christmas': 259, 'yen': 260, 'legs': 261, 'spider': 262, 'sport': 263, 'uses': 264, 'net,': 265, 'ball,': 266, 'hoop': 267, 'basketball': 268, 'kangaroos': 269, 'female': 270, 'minister': 271, 'uk': 272, 'margaretthatcher': 273, 'fastest': 274, 'animal': 275, 'cheetah': 276, 'periodic': 277, 'table': 278, 'spain': 279, 'madrid': 280, 'closest': 281, 'sun': 282, 'father': 283, 'computers': 284, 'charlesbabbage': 285, 'mexico': 286, 'mexicocity': 287, 'colors': 288, 'rainbow': 289, 'musical': 290, 'instrument': 291, 'black': 292, 'white': 293, 'keys': 294, 'piano': 295, 'americas': 296, '1492': 297, 'christophercolumbus': 298, 'disney': 299, 'character': 300, 'long': 301, 'nose': 302, 'grows': 303, 'it': 304, 'when': 305, 'lying': 306, 'pinocchio': 307, 'directed': 308, 'movie': 309, 'titanic': 310, 'jamescameron': 311, 'superhero': 312, 'also': 313, 'dark': 314, 'knight': 315, 'batman': 316, 'brasilia': 317, 'fruit': 318, 'king': 319, 'fruits': 320, 'mango': 321, 'eiffel': 322, 'tower': 323}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_indices(text, vocab= vocab):\n",
    "    indexed_text = []\n",
    "\n",
    "    for token in tokenizer(text):\n",
    "\n",
    "        if token in vocab.keys():\n",
    "            indexed_text.append(vocab[token])\n",
    "        else:\n",
    "            indexed_text.append(0)\n",
    "\n",
    "    return indexed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_indices(\"Hello Bro\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 81, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_indices(\"what are you doing?\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of Germany?</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
       "      <td>Harper-Lee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>Jupiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the boiling point of water in Celsius?</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Who directed the movie 'Titanic'?</td>\n",
       "      <td>JamesCameron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Which superhero is also known as the Dark Knight?</td>\n",
       "      <td>Batman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>What is the capital of Brazil?</td>\n",
       "      <td>Brasilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Which fruit is known as the king of fruits?</td>\n",
       "      <td>Mango</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Which country is known for the Eiffel Tower?</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question        answer\n",
       "0                      What is the capital of France?         Paris\n",
       "1                     What is the capital of Germany?        Berlin\n",
       "2                  Who wrote 'To Kill a Mockingbird'?    Harper-Lee\n",
       "3     What is the largest planet in our solar system?       Jupiter\n",
       "4      What is the boiling point of water in Celsius?           100\n",
       "..                                                ...           ...\n",
       "85                  Who directed the movie 'Titanic'?  JamesCameron\n",
       "86  Which superhero is also known as the Dark Knight?        Batman\n",
       "87                     What is the capital of Brazil?      Brasilia\n",
       "88        Which fruit is known as the king of fruits?         Mango\n",
       "89       Which country is known for the Eiffel Tower?        France\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, vocab):\n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        numerical_question = text_to_indices(self.data.iloc[index][\"question\"], self.vocab)\n",
    "\n",
    "        numerical_answer = text_to_indices(self.data.iloc[index][\"answer\"], self.vocab)\n",
    "\n",
    "        return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QADataset(data, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x21f2d1a0700>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset=dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
      "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
      "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
      "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
      "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
      "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
      "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
      "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
      "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
      "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
      "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
      "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
      "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
      "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
      "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
      "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
      "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
      "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
      "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
      "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
      "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
      "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
      "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
      "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
      "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
      "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n",
      "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
      "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
      "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
      "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
      "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
      "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
      "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
      "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
      "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
      "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
      "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n",
      "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
      "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
      "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
      "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
      "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
      "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
      "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
      "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
      "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
      "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
      "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
      "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
      "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
      "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
      "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
      "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
      "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
      "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
      "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
      "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
      "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
      "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
      "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
      "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
      "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
      "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
      "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
      "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
      "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
      "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
      "tensor([[10, 75, 76]]) tensor([[77]])\n",
      "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
      "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
      "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
      "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
      "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
      "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
      "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
      "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
      "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
      "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
      "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
      "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
      "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
      "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
      "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
      "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
      "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
      "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n"
     ]
    }
   ],
   "source": [
    "for question, answer in dataloader:\n",
    "    print(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RNN Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, 50)\n",
    "        self.rnn = nn.RNN(50,64)\n",
    "        self.fc = nn.Linear(64, vocab_size)\n",
    "    \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.Embedding(324, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0621, -0.7427,  0.2121,  0.8294,  0.3969, -0.7774,  0.6204,  1.2912,\n",
       "          0.0299, -0.9470, -1.0739, -0.8856,  0.1457,  0.5873, -1.3774,  0.3687,\n",
       "         -0.5773, -0.7195, -0.4101, -0.4019, -1.5068,  0.5913, -0.2260,  0.5965,\n",
       "          1.4326, -0.0757, -0.0316,  0.7341,  1.5086, -0.1661,  1.4666, -1.2047,\n",
       "          0.7110,  0.7187, -1.3652, -0.8472,  2.1517, -2.8920,  0.7809,  0.1302,\n",
       "         -0.0712, -1.2409,  0.0439, -0.1625,  0.4222,  0.7002, -0.6309,  0.1296,\n",
       "         -1.5759, -0.3125],\n",
       "        [-0.8526,  0.0535,  2.3013, -0.9323, -1.5039,  0.1026, -0.2821,  0.1111,\n",
       "         -0.3175, -0.0659, -1.3438, -0.6470, -1.0736, -0.9502, -0.1284, -1.8788,\n",
       "          0.8402, -0.7376,  2.0433,  0.8176,  1.1893, -2.7850,  0.9778, -0.3563,\n",
       "         -0.1651, -0.2396, -0.2400, -0.2247,  0.8292, -2.3022, -0.1794, -1.1799,\n",
       "         -0.2787,  0.5147, -0.0519, -0.3777, -0.1250, -1.7501, -0.1389,  0.5590,\n",
       "          1.8613, -0.1705,  0.1126,  1.0943, -1.7425, -0.4176,  0.9169, -0.0896,\n",
       "         -0.1222, -2.1258],\n",
       "        [-0.4165,  0.4808, -0.7114,  1.4875, -0.9037, -0.5548,  1.4472, -0.1756,\n",
       "         -1.0944,  0.0140, -1.0009, -0.2429, -0.3047,  0.1249,  0.4596, -0.6492,\n",
       "         -0.4138, -0.6402,  0.9320,  0.3445, -0.2548, -1.3799,  0.0908,  0.1437,\n",
       "          1.3921,  0.3011,  0.3741,  0.6253, -0.9177, -0.1824,  0.2211,  1.6468,\n",
       "         -0.6533,  0.3606,  0.0938, -0.6130,  1.8491,  2.5441, -0.1329,  0.5835,\n",
       "          1.0028,  1.9319, -0.2159,  0.2958, -0.7703, -0.8501,  0.4321, -0.3532,\n",
       "          0.4627, -0.5507],\n",
       "        [ 0.3983, -0.2564, -0.6730,  0.1482, -1.3293,  0.7549,  2.1616,  0.1288,\n",
       "          1.7707, -1.0973, -0.2724, -0.2338,  0.8137, -0.5499,  0.2832,  2.3997,\n",
       "          0.1561,  1.7587,  0.3027, -1.9029,  1.0959, -0.3875, -0.8346,  1.7632,\n",
       "          1.0667, -1.9350,  0.7070,  0.2740,  2.0023,  0.0389, -1.2132,  0.5266,\n",
       "         -0.7228, -0.5019,  1.3169, -0.5260,  0.1587, -0.6612,  0.2058,  1.4968,\n",
       "         -1.3524, -1.7206, -0.8618, -0.9543, -0.3056,  1.3044,  0.4695,  0.3480,\n",
       "          0.0072, -0.1013],\n",
       "        [ 0.8846, -0.1620,  0.3975, -0.6744,  1.1709, -0.6120, -0.5223,  1.0938,\n",
       "         -0.2295,  0.4215, -0.9957, -0.8548,  1.4788,  0.3055, -1.2627, -0.7227,\n",
       "         -0.7469, -0.7348, -1.2501,  0.3529,  1.2821, -0.3715,  1.9182, -0.7870,\n",
       "          0.0797,  0.0401, -1.5142, -1.1570, -1.0794, -0.8362, -1.1750, -2.0330,\n",
       "          1.4335,  1.7747,  0.5907, -0.0928, -1.1839,  0.3069, -0.7611, -0.0998,\n",
       "          0.7281, -0.1335, -0.9616,  1.1511,  1.7018, -2.2386,  0.0414, -1.5752,\n",
       "          0.6900,  0.8920],\n",
       "        [-0.8821,  0.1515, -1.5520, -1.1111, -0.1909,  1.8109, -2.1146,  0.4477,\n",
       "         -0.2836,  0.9221, -0.4072, -1.1559, -1.0341,  1.3386, -0.5702, -1.6153,\n",
       "         -1.0070,  0.7463, -2.7571, -0.5239, -0.2912,  0.3607, -0.9531,  0.1928,\n",
       "         -1.0299,  0.2270, -0.9941,  0.2264, -1.4140,  0.4716, -2.1677, -1.0225,\n",
       "          0.1947,  1.0956,  1.2913, -1.5648, -0.1451, -0.1849,  0.2744, -0.1581,\n",
       "         -1.2559, -1.0779, -0.8038, -0.6905,  0.0081,  1.2610, -1.7619, -0.8545,\n",
       "         -0.9562,  0.3949]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x(dataset[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x(dataset[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x(dataset[17][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 75, 76])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[17][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0621, -0.7427,  0.2121,  0.8294,  0.3969, -0.7774,  0.6204,  1.2912,\n",
       "          0.0299, -0.9470, -1.0739, -0.8856,  0.1457,  0.5873, -1.3774,  0.3687,\n",
       "         -0.5773, -0.7195, -0.4101, -0.4019, -1.5068,  0.5913, -0.2260,  0.5965,\n",
       "          1.4326, -0.0757, -0.0316,  0.7341,  1.5086, -0.1661,  1.4666, -1.2047,\n",
       "          0.7110,  0.7187, -1.3652, -0.8472,  2.1517, -2.8920,  0.7809,  0.1302,\n",
       "         -0.0712, -1.2409,  0.0439, -0.1625,  0.4222,  0.7002, -0.6309,  0.1296,\n",
       "         -1.5759, -0.3125],\n",
       "        [-0.8526,  0.0535,  2.3013, -0.9323, -1.5039,  0.1026, -0.2821,  0.1111,\n",
       "         -0.3175, -0.0659, -1.3438, -0.6470, -1.0736, -0.9502, -0.1284, -1.8788,\n",
       "          0.8402, -0.7376,  2.0433,  0.8176,  1.1893, -2.7850,  0.9778, -0.3563,\n",
       "         -0.1651, -0.2396, -0.2400, -0.2247,  0.8292, -2.3022, -0.1794, -1.1799,\n",
       "         -0.2787,  0.5147, -0.0519, -0.3777, -0.1250, -1.7501, -0.1389,  0.5590,\n",
       "          1.8613, -0.1705,  0.1126,  1.0943, -1.7425, -0.4176,  0.9169, -0.0896,\n",
       "         -0.1222, -2.1258],\n",
       "        [-0.4165,  0.4808, -0.7114,  1.4875, -0.9037, -0.5548,  1.4472, -0.1756,\n",
       "         -1.0944,  0.0140, -1.0009, -0.2429, -0.3047,  0.1249,  0.4596, -0.6492,\n",
       "         -0.4138, -0.6402,  0.9320,  0.3445, -0.2548, -1.3799,  0.0908,  0.1437,\n",
       "          1.3921,  0.3011,  0.3741,  0.6253, -0.9177, -0.1824,  0.2211,  1.6468,\n",
       "         -0.6533,  0.3606,  0.0938, -0.6130,  1.8491,  2.5441, -0.1329,  0.5835,\n",
       "          1.0028,  1.9319, -0.2159,  0.2958, -0.7703, -0.8501,  0.4321, -0.3532,\n",
       "          0.4627, -0.5507],\n",
       "        [ 0.3983, -0.2564, -0.6730,  0.1482, -1.3293,  0.7549,  2.1616,  0.1288,\n",
       "          1.7707, -1.0973, -0.2724, -0.2338,  0.8137, -0.5499,  0.2832,  2.3997,\n",
       "          0.1561,  1.7587,  0.3027, -1.9029,  1.0959, -0.3875, -0.8346,  1.7632,\n",
       "          1.0667, -1.9350,  0.7070,  0.2740,  2.0023,  0.0389, -1.2132,  0.5266,\n",
       "         -0.7228, -0.5019,  1.3169, -0.5260,  0.1587, -0.6612,  0.2058,  1.4968,\n",
       "         -1.3524, -1.7206, -0.8618, -0.9543, -0.3056,  1.3044,  0.4695,  0.3480,\n",
       "          0.0072, -0.1013],\n",
       "        [ 0.8846, -0.1620,  0.3975, -0.6744,  1.1709, -0.6120, -0.5223,  1.0938,\n",
       "         -0.2295,  0.4215, -0.9957, -0.8548,  1.4788,  0.3055, -1.2627, -0.7227,\n",
       "         -0.7469, -0.7348, -1.2501,  0.3529,  1.2821, -0.3715,  1.9182, -0.7870,\n",
       "          0.0797,  0.0401, -1.5142, -1.1570, -1.0794, -0.8362, -1.1750, -2.0330,\n",
       "          1.4335,  1.7747,  0.5907, -0.0928, -1.1839,  0.3069, -0.7611, -0.0998,\n",
       "          0.7281, -0.1335, -0.9616,  1.1511,  1.7018, -2.2386,  0.0414, -1.5752,\n",
       "          0.6900,  0.8920],\n",
       "        [-0.8821,  0.1515, -1.5520, -1.1111, -0.1909,  1.8109, -2.1146,  0.4477,\n",
       "         -0.2836,  0.9221, -0.4072, -1.1559, -1.0341,  1.3386, -0.5702, -1.6153,\n",
       "         -1.0070,  0.7463, -2.7571, -0.5239, -0.2912,  0.3607, -0.9531,  0.1928,\n",
       "         -1.0299,  0.2270, -0.9941,  0.2264, -1.4140,  0.4716, -2.1677, -1.0225,\n",
       "          0.1947,  1.0956,  1.2913, -1.5648, -0.1451, -0.1849,  0.2744, -0.1581,\n",
       "         -1.2559, -1.0779, -0.8038, -0.6905,  0.0081,  1.2610, -1.7619, -0.8545,\n",
       "         -0.9562,  0.3949]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x(dataset[0][0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nn.RNN(50,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7582,  0.0106,  0.1175,  0.0665,  0.5176, -0.2352,  0.7940,  0.1266,\n",
       "          -0.1372,  0.5551, -0.0764, -0.6043,  0.3012, -0.2871, -0.3280, -0.7240,\n",
       "          -0.0642, -0.5721,  0.1801,  0.1043,  0.0148,  0.3511,  0.0631,  0.0646,\n",
       "          -0.4578, -0.5183,  0.4811, -0.1907, -0.5849,  0.3604,  0.1271, -0.5093,\n",
       "          -0.5934,  0.0985, -0.6398, -0.6216, -0.1749,  0.1441, -0.2551, -0.5052,\n",
       "           0.5427, -0.3812,  0.0859,  0.2571, -0.2822, -0.0867,  0.3776, -0.6227,\n",
       "           0.3754, -0.5618, -0.1449,  0.4801,  0.1361,  0.7683,  0.7132,  0.1830,\n",
       "          -0.4308, -0.4199,  0.3710, -0.2537,  0.3576,  0.3167,  0.4798, -0.4393],\n",
       "         [ 0.5783, -0.7445, -0.1654, -0.0263,  0.0071, -0.1196, -0.6305,  0.2348,\n",
       "           0.7108,  0.7858, -0.6345, -0.3477, -0.3519, -0.2200,  0.8256, -0.1633,\n",
       "           0.5795,  0.1401, -0.1655,  0.2812,  0.6416, -0.4351,  0.5532, -0.7994,\n",
       "          -0.0186, -0.5728, -0.5099, -0.0507,  0.0487,  0.8425,  0.7070, -0.3187,\n",
       "          -0.8239,  0.0039, -0.0204, -0.1882,  0.0741,  0.5481, -0.7801, -0.3117,\n",
       "          -0.4884, -0.2427,  0.8688, -0.6264, -0.4651,  0.2154, -0.0273, -0.0785,\n",
       "          -0.8782, -0.5866,  0.4899,  0.0242, -0.3385,  0.0670,  0.5544, -0.2249,\n",
       "          -0.7005, -0.3428, -0.8259, -0.3218,  0.5243,  0.0079,  0.7973, -0.2788],\n",
       "         [ 0.0889, -0.6416,  0.2102,  0.8510,  0.1718,  0.0657, -0.1955,  0.6294,\n",
       "          -0.0615,  0.2170,  0.0782, -0.3254,  0.5107,  0.6212, -0.0454,  0.4947,\n",
       "           0.4347, -0.8100,  0.7504,  0.6324,  0.0894, -0.8698,  0.2645,  0.5390,\n",
       "          -0.1519,  0.3193, -0.1398, -0.2188, -0.3052, -0.2028, -0.0627, -0.2976,\n",
       "          -0.0680,  0.2127, -0.2334, -0.3652,  0.4094, -0.6844, -0.5416, -0.4747,\n",
       "          -0.7902,  0.4704, -0.3801, -0.5458, -0.3798,  0.1648, -0.1657,  0.3828,\n",
       "          -0.2485, -0.6679,  0.5236,  0.3627, -0.5651,  0.2285, -0.0952, -0.2840,\n",
       "           0.2055,  0.8427, -0.1024, -0.0842,  0.1691, -0.3495,  0.2912,  0.1725],\n",
       "         [-0.8789, -0.0546, -0.7187, -0.4431, -0.4373,  0.7623,  0.3253, -0.0041,\n",
       "          -0.7356,  0.5019, -0.3771, -0.1271,  0.4114,  0.1685,  0.1876, -0.7735,\n",
       "           0.3870, -0.2824,  0.9064, -0.0800,  0.4000, -0.3355, -0.3810,  0.3864,\n",
       "          -0.2075,  0.2080,  0.4597,  0.5178,  0.0168, -0.8350, -0.5048, -0.3970,\n",
       "          -0.4016, -0.6173, -0.3959, -0.4423,  0.7194,  0.0197, -0.3595, -0.4173,\n",
       "          -0.3522, -0.6040,  0.5194, -0.1099,  0.2169,  0.3566,  0.3941,  0.7745,\n",
       "           0.4985, -0.2524, -0.1883,  0.8171,  0.2947, -0.6176, -0.2841, -0.3451,\n",
       "          -0.2190,  0.3610, -0.4355, -0.0461, -0.2560, -0.8049,  0.8323, -0.7240],\n",
       "         [ 0.1383, -0.5879, -0.1097, -0.3687,  0.6389, -0.8774, -0.2847, -0.2590,\n",
       "           0.1346, -0.4707,  0.6407,  0.5816,  0.9409,  0.1605,  0.5111,  0.2184,\n",
       "           0.1030,  0.6545, -0.7651, -0.7614,  0.8470,  0.6357, -0.2991, -0.7989,\n",
       "          -0.5693,  0.5653,  0.1872,  0.7441,  0.6151, -0.6018,  0.3152, -0.3680,\n",
       "          -0.2777,  0.4248, -0.3855, -0.3588,  0.8735,  0.0806, -0.0223, -0.0466,\n",
       "           0.6012, -0.3525,  0.6326,  0.5228,  0.0228,  0.0968, -0.2252, -0.0253,\n",
       "          -0.7757,  0.1241, -0.4135, -0.3588,  0.4429, -0.3203,  0.6611, -0.2011,\n",
       "           0.3346,  0.2416, -0.0211,  0.5367,  0.6562,  0.4015, -0.6055, -0.5425],\n",
       "         [-0.0931,  0.3695, -0.0796, -0.4695,  0.6362, -0.7905, -0.8241, -0.1165,\n",
       "           0.7327,  0.0240, -0.5103,  0.6462,  0.3690, -0.0809, -0.1801, -0.2828,\n",
       "           0.2258, -0.1833,  0.0947,  0.7829,  0.3282, -0.0721,  0.1956, -0.5023,\n",
       "           0.3788,  0.8920,  0.8579,  0.0197,  0.2646, -0.6914, -0.5154,  0.4494,\n",
       "           0.2058,  0.2976, -0.7672, -0.2452,  0.3046,  0.6955,  0.5416,  0.0878,\n",
       "           0.8952,  0.0897,  0.3136,  0.0248, -0.4917, -0.4041, -0.0407, -0.4497,\n",
       "           0.7078,  0.3850,  0.0647, -0.6471, -0.3927, -0.6475,  0.0171,  0.4565,\n",
       "           0.3090, -0.0071,  0.3795,  0.0255,  0.3940,  0.2355, -0.7120, -0.4200]],\n",
       "        grad_fn=<SqueezeBackward1>),\n",
       " tensor([[-0.0931,  0.3695, -0.0796, -0.4695,  0.6362, -0.7905, -0.8241, -0.1165,\n",
       "           0.7327,  0.0240, -0.5103,  0.6462,  0.3690, -0.0809, -0.1801, -0.2828,\n",
       "           0.2258, -0.1833,  0.0947,  0.7829,  0.3282, -0.0721,  0.1956, -0.5023,\n",
       "           0.3788,  0.8920,  0.8579,  0.0197,  0.2646, -0.6914, -0.5154,  0.4494,\n",
       "           0.2058,  0.2976, -0.7672, -0.2452,  0.3046,  0.6955,  0.5416,  0.0878,\n",
       "           0.8952,  0.0897,  0.3136,  0.0248, -0.4917, -0.4041, -0.0407, -0.4497,\n",
       "           0.7078,  0.3850,  0.0647, -0.6471, -0.3927, -0.6475,  0.0171,  0.4565,\n",
       "           0.3090, -0.0071,  0.3795,  0.0255,  0.3940,  0.2355, -0.7120, -0.4200]],\n",
       "        grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = y(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7582,  0.0106,  0.1175,  0.0665,  0.5176, -0.2352,  0.7940,  0.1266,\n",
       "         -0.1372,  0.5551, -0.0764, -0.6043,  0.3012, -0.2871, -0.3280, -0.7240,\n",
       "         -0.0642, -0.5721,  0.1801,  0.1043,  0.0148,  0.3511,  0.0631,  0.0646,\n",
       "         -0.4578, -0.5183,  0.4811, -0.1907, -0.5849,  0.3604,  0.1271, -0.5093,\n",
       "         -0.5934,  0.0985, -0.6398, -0.6216, -0.1749,  0.1441, -0.2551, -0.5052,\n",
       "          0.5427, -0.3812,  0.0859,  0.2571, -0.2822, -0.0867,  0.3776, -0.6227,\n",
       "          0.3754, -0.5618, -0.1449,  0.4801,  0.1361,  0.7683,  0.7132,  0.1830,\n",
       "         -0.4308, -0.4199,  0.3710, -0.2537,  0.3576,  0.3167,  0.4798, -0.4393],\n",
       "        [ 0.5783, -0.7445, -0.1654, -0.0263,  0.0071, -0.1196, -0.6305,  0.2348,\n",
       "          0.7108,  0.7858, -0.6345, -0.3477, -0.3519, -0.2200,  0.8256, -0.1633,\n",
       "          0.5795,  0.1401, -0.1655,  0.2812,  0.6416, -0.4351,  0.5532, -0.7994,\n",
       "         -0.0186, -0.5728, -0.5099, -0.0507,  0.0487,  0.8425,  0.7070, -0.3187,\n",
       "         -0.8239,  0.0039, -0.0204, -0.1882,  0.0741,  0.5481, -0.7801, -0.3117,\n",
       "         -0.4884, -0.2427,  0.8688, -0.6264, -0.4651,  0.2154, -0.0273, -0.0785,\n",
       "         -0.8782, -0.5866,  0.4899,  0.0242, -0.3385,  0.0670,  0.5544, -0.2249,\n",
       "         -0.7005, -0.3428, -0.8259, -0.3218,  0.5243,  0.0079,  0.7973, -0.2788],\n",
       "        [ 0.0889, -0.6416,  0.2102,  0.8510,  0.1718,  0.0657, -0.1955,  0.6294,\n",
       "         -0.0615,  0.2170,  0.0782, -0.3254,  0.5107,  0.6212, -0.0454,  0.4947,\n",
       "          0.4347, -0.8100,  0.7504,  0.6324,  0.0894, -0.8698,  0.2645,  0.5390,\n",
       "         -0.1519,  0.3193, -0.1398, -0.2188, -0.3052, -0.2028, -0.0627, -0.2976,\n",
       "         -0.0680,  0.2127, -0.2334, -0.3652,  0.4094, -0.6844, -0.5416, -0.4747,\n",
       "         -0.7902,  0.4704, -0.3801, -0.5458, -0.3798,  0.1648, -0.1657,  0.3828,\n",
       "         -0.2485, -0.6679,  0.5236,  0.3627, -0.5651,  0.2285, -0.0952, -0.2840,\n",
       "          0.2055,  0.8427, -0.1024, -0.0842,  0.1691, -0.3495,  0.2912,  0.1725],\n",
       "        [-0.8789, -0.0546, -0.7187, -0.4431, -0.4373,  0.7623,  0.3253, -0.0041,\n",
       "         -0.7356,  0.5019, -0.3771, -0.1271,  0.4114,  0.1685,  0.1876, -0.7735,\n",
       "          0.3870, -0.2824,  0.9064, -0.0800,  0.4000, -0.3355, -0.3810,  0.3864,\n",
       "         -0.2075,  0.2080,  0.4597,  0.5178,  0.0168, -0.8350, -0.5048, -0.3970,\n",
       "         -0.4016, -0.6173, -0.3959, -0.4423,  0.7194,  0.0197, -0.3595, -0.4173,\n",
       "         -0.3522, -0.6040,  0.5194, -0.1099,  0.2169,  0.3566,  0.3941,  0.7745,\n",
       "          0.4985, -0.2524, -0.1883,  0.8171,  0.2947, -0.6176, -0.2841, -0.3451,\n",
       "         -0.2190,  0.3610, -0.4355, -0.0461, -0.2560, -0.8049,  0.8323, -0.7240],\n",
       "        [ 0.1383, -0.5879, -0.1097, -0.3687,  0.6389, -0.8774, -0.2847, -0.2590,\n",
       "          0.1346, -0.4707,  0.6407,  0.5816,  0.9409,  0.1605,  0.5111,  0.2184,\n",
       "          0.1030,  0.6545, -0.7651, -0.7614,  0.8470,  0.6357, -0.2991, -0.7989,\n",
       "         -0.5693,  0.5653,  0.1872,  0.7441,  0.6151, -0.6018,  0.3152, -0.3680,\n",
       "         -0.2777,  0.4248, -0.3855, -0.3588,  0.8735,  0.0806, -0.0223, -0.0466,\n",
       "          0.6012, -0.3525,  0.6326,  0.5228,  0.0228,  0.0968, -0.2252, -0.0253,\n",
       "         -0.7757,  0.1241, -0.4135, -0.3588,  0.4429, -0.3203,  0.6611, -0.2011,\n",
       "          0.3346,  0.2416, -0.0211,  0.5367,  0.6562,  0.4015, -0.6055, -0.5425],\n",
       "        [-0.0931,  0.3695, -0.0796, -0.4695,  0.6362, -0.7905, -0.8241, -0.1165,\n",
       "          0.7327,  0.0240, -0.5103,  0.6462,  0.3690, -0.0809, -0.1801, -0.2828,\n",
       "          0.2258, -0.1833,  0.0947,  0.7829,  0.3282, -0.0721,  0.1956, -0.5023,\n",
       "          0.3788,  0.8920,  0.8579,  0.0197,  0.2646, -0.6914, -0.5154,  0.4494,\n",
       "          0.2058,  0.2976, -0.7672, -0.2452,  0.3046,  0.6955,  0.5416,  0.0878,\n",
       "          0.8952,  0.0897,  0.3136,  0.0248, -0.4917, -0.4041, -0.0407, -0.4497,\n",
       "          0.7078,  0.3850,  0.0647, -0.6471, -0.3927, -0.6475,  0.0171,  0.4565,\n",
       "          0.3090, -0.0071,  0.3795,  0.0255,  0.3940,  0.2355, -0.7120, -0.4200]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0]  ## this are the hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0931,  0.3695, -0.0796, -0.4695,  0.6362, -0.7905, -0.8241, -0.1165,\n",
       "          0.7327,  0.0240, -0.5103,  0.6462,  0.3690, -0.0809, -0.1801, -0.2828,\n",
       "          0.2258, -0.1833,  0.0947,  0.7829,  0.3282, -0.0721,  0.1956, -0.5023,\n",
       "          0.3788,  0.8920,  0.8579,  0.0197,  0.2646, -0.6914, -0.5154,  0.4494,\n",
       "          0.2058,  0.2976, -0.7672, -0.2452,  0.3046,  0.6955,  0.5416,  0.0878,\n",
       "          0.8952,  0.0897,  0.3136,  0.0248, -0.4917, -0.4041, -0.0407, -0.4497,\n",
       "          0.7078,  0.3850,  0.0647, -0.6471, -0.3927, -0.6475,  0.0171,  0.4565,\n",
       "          0.3090, -0.0071,  0.3795,  0.0255,  0.3940,  0.2355, -0.7120, -0.4200]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1] ## this is the hidden state of the last time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape, b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in rnn we pass the input in form of time steps one by one\n",
    "## so we have first we have 6 words and we convert each word into 50 dim vector\n",
    "## so we have 6*50 dim vector\n",
    "## now we pass this to rnn and get the output and we get both hidden states and the final output states\n",
    "# after passing through the rnn we get the output of 1*64 dim vector\n",
    "## now we pass this to the linear layer and get the output of vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## so we need to pass the hidden state of the last time step to the fully connected layer\n",
    "## this will be the input to the fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=64, out_features=324, bias=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = nn.Linear(64, 324)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.1781e-02, -1.8217e-02,  3.4726e-01,  1.0153e-01,  7.3660e-03,\n",
       "         -1.2130e-02, -3.2297e-01, -2.0542e-01, -4.1461e-01, -1.2326e-01,\n",
       "          8.4545e-02, -3.4144e-02, -2.4872e-01, -2.1583e-01, -2.2227e-01,\n",
       "          2.7429e-01, -6.3701e-01, -1.1361e-01,  5.2409e-02,  5.2254e-01,\n",
       "          2.7719e-01,  5.6149e-02,  3.6041e-01, -2.1452e-01,  1.3011e-01,\n",
       "          2.1814e-01,  2.6714e-01, -8.0143e-03, -9.0027e-02,  1.9925e-02,\n",
       "          1.8504e-01, -7.1738e-01,  4.8499e-02, -6.3305e-01,  1.9920e-01,\n",
       "         -5.1527e-01, -1.8398e-01,  3.4664e-01, -4.3962e-01,  1.6305e-01,\n",
       "          3.7175e-04,  1.5142e-01, -8.0838e-02,  2.9616e-01, -1.5816e-01,\n",
       "          3.8022e-01,  5.3197e-01, -1.0072e-01, -7.6375e-02,  4.7947e-01,\n",
       "          9.8064e-02, -3.8944e-02,  1.2730e-01, -4.7630e-01,  8.2522e-02,\n",
       "          4.9854e-02, -3.4218e-02,  9.8782e-02, -2.6045e-01,  4.9358e-01,\n",
       "          4.1057e-02, -2.8656e-01, -5.2371e-02, -3.9260e-01, -7.8172e-02,\n",
       "          9.5577e-02, -2.6691e-01,  3.5016e-01,  1.2386e-02, -3.3277e-01,\n",
       "         -5.8560e-03,  2.1786e-01, -1.1596e-01,  6.1423e-02,  4.4962e-01,\n",
       "         -3.2717e-01,  1.0285e-01,  3.9686e-01,  3.5788e-01,  5.2420e-02,\n",
       "         -6.0696e-02,  1.3571e-01, -7.0765e-01,  1.8082e-01,  5.1792e-01,\n",
       "          2.1120e-01, -1.3646e-01, -3.2233e-01,  8.0215e-02,  6.7222e-01,\n",
       "          1.1916e-01,  1.8803e-01, -2.1225e-01,  2.5578e-01, -4.5756e-01,\n",
       "         -3.1507e-01,  1.1995e-01,  2.4639e-01, -1.3082e-01,  6.3391e-02,\n",
       "          5.8129e-01,  3.3775e-01, -3.0010e-01, -3.5756e-01,  3.0033e-01,\n",
       "          3.7248e-01, -5.9466e-01, -2.1024e-01, -1.1118e-01, -2.1700e-01,\n",
       "         -1.0748e-01,  1.3562e-02,  3.7590e-01,  2.5839e-02, -1.6305e-01,\n",
       "          4.9344e-01, -3.9026e-01,  3.0532e-02, -2.0391e-03, -1.9394e-01,\n",
       "         -7.3521e-01,  1.0172e-01, -4.6591e-02, -1.6443e-01, -1.3413e-01,\n",
       "          2.3998e-01, -8.9075e-02, -1.2290e-01, -3.7736e-01,  6.1920e-02,\n",
       "         -3.2953e-01,  6.9475e-01,  2.7939e-01, -5.0072e-01,  3.4420e-01,\n",
       "         -4.8707e-02,  3.1900e-02, -7.3205e-03,  3.4709e-01, -4.1341e-01,\n",
       "         -1.7801e-01,  3.9295e-02, -5.7486e-01, -2.1043e-01,  3.8566e-01,\n",
       "          6.0303e-01,  3.1342e-01,  1.9353e-01, -2.0236e-01,  5.7943e-01,\n",
       "          4.5985e-01,  1.1708e-01, -4.9479e-01, -3.5363e-01,  2.2549e-01,\n",
       "         -1.5747e-01, -4.7786e-01, -3.3445e-01, -8.9943e-03, -6.8693e-02,\n",
       "          4.9365e-01, -3.7133e-01, -2.5623e-01, -1.8486e-02, -4.4118e-01,\n",
       "          1.3146e-01,  3.3587e-01,  8.9757e-02,  7.1269e-02, -5.3558e-02,\n",
       "          1.1335e-02, -1.8104e-01, -4.2860e-01, -1.4075e-01,  1.1014e-01,\n",
       "         -6.0301e-01, -1.6561e-01, -3.7934e-02,  4.7382e-01, -7.0928e-01,\n",
       "          3.3007e-01,  4.4274e-01, -1.9481e-02, -4.4605e-01, -2.4276e-01,\n",
       "         -4.6598e-01,  4.6003e-03,  5.1770e-01,  3.1119e-01,  5.3783e-01,\n",
       "         -1.5477e-01,  2.4188e-01,  5.4173e-03,  3.2982e-01, -1.3687e-01,\n",
       "          2.3894e-02, -2.6484e-01,  2.0665e-01, -1.0537e-01,  5.5308e-02,\n",
       "          8.1581e-02,  2.8749e-01, -2.1411e-01, -4.0677e-01, -1.3979e-01,\n",
       "         -1.0448e-01, -1.8707e-01,  1.0143e-01,  2.2136e-01,  1.1702e-01,\n",
       "         -3.2838e-01,  6.6328e-02, -2.1829e-01,  6.7311e-01, -2.7833e-01,\n",
       "         -8.1574e-02, -1.1087e-01, -5.3297e-02,  1.1037e-01, -4.2880e-01,\n",
       "         -5.9729e-01,  4.6097e-01,  3.5176e-01, -6.0356e-02, -7.7368e-02,\n",
       "          1.5991e-01,  6.1985e-01,  2.1012e-01,  3.0567e-01,  1.0816e-02,\n",
       "         -2.2734e-01,  3.7907e-02,  1.2886e-01, -4.6819e-01,  1.4392e-01,\n",
       "         -2.2899e-01, -2.2335e-01, -5.5267e-01, -4.5819e-02,  4.8525e-02,\n",
       "         -1.4938e-01,  1.7527e-01,  2.1604e-01, -3.5145e-02, -7.6077e-02,\n",
       "         -5.9428e-02,  1.3131e-01, -2.8287e-01, -1.8276e-01, -2.5988e-02,\n",
       "         -9.3640e-02,  7.9044e-02, -1.5733e-01,  8.0006e-02, -2.0567e-01,\n",
       "         -3.8484e-03,  5.2526e-01, -9.3252e-02,  4.4528e-01, -3.2385e-01,\n",
       "         -4.2381e-04,  1.2569e-01,  5.9181e-02, -8.3266e-02,  1.0285e-01,\n",
       "         -1.7060e-01,  2.4069e-01, -1.8824e-01,  1.3742e-01, -6.1828e-01,\n",
       "          8.5821e-02,  1.2229e-01, -6.4196e-02, -1.8525e-01,  1.9099e-01,\n",
       "         -2.9133e-01,  3.2392e-01, -1.5719e-01, -9.0272e-01,  2.5192e-01,\n",
       "          2.3993e-01,  1.6985e-01,  3.8876e-01, -5.0617e-01, -3.5476e-01,\n",
       "         -8.6438e-02,  3.0144e-01,  4.5861e-01,  2.8990e-01,  3.7540e-01,\n",
       "         -2.3485e-01, -4.9767e-01,  2.0529e-01,  5.6719e-02,  5.7848e-02,\n",
       "          3.2483e-01, -1.1644e-02,  3.5405e-01,  5.5576e-03,  6.5618e-02,\n",
       "         -2.0923e-01,  6.0077e-01, -3.1075e-01,  3.3414e-01,  1.1050e-01,\n",
       "          2.7011e-01,  1.5400e-01,  4.3832e-01,  1.7831e-01, -2.4666e-01,\n",
       "         -1.5774e-01, -5.6237e-02,  2.9141e-01,  2.5124e-01,  2.2263e-02,\n",
       "          4.1937e-04, -2.5440e-01,  2.2529e-01, -4.4492e-01, -1.7359e-01,\n",
       "          2.7696e-01,  8.3322e-02,  1.1459e-01,  2.2820e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = z(b[1])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0931,  0.3695, -0.0796, -0.4695,  0.6362, -0.7905, -0.8241, -0.1165,\n",
       "          0.7327,  0.0240, -0.5103,  0.6462,  0.3690, -0.0809, -0.1801, -0.2828,\n",
       "          0.2258, -0.1833,  0.0947,  0.7829,  0.3282, -0.0721,  0.1956, -0.5023,\n",
       "          0.3788,  0.8920,  0.8579,  0.0197,  0.2646, -0.6914, -0.5154,  0.4494,\n",
       "          0.2058,  0.2976, -0.7672, -0.2452,  0.3046,  0.6955,  0.5416,  0.0878,\n",
       "          0.8952,  0.0897,  0.3136,  0.0248, -0.4917, -0.4041, -0.0407, -0.4497,\n",
       "          0.7078,  0.3850,  0.0647, -0.6471, -0.3927, -0.6475,  0.0171,  0.4565,\n",
       "          0.3090, -0.0071,  0.3795,  0.0255,  0.3940,  0.2355, -0.7120, -0.4200]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 324])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.6947], grad_fn=<MaxBackward0>),\n",
       "indices=tensor([131]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, 50)\n",
    "        self.rnn = nn.RNN(50,64, batch_first=True)\n",
    "        self.fc = nn.Linear(64, vocab_size)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        embedding = self.embed(question)\n",
    "        hidden, final = self.rnn(embedding)\n",
    "        output = self.fc(final[-1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 20)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "learning_rate, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embed): Embedding(324, 50)\n",
       "  (rnn): RNN(50, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=324, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(len(vocab))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1 | loss : 0.4186107061834049\n",
      "epoch : 2 | loss : 0.4532295361126248\n",
      "epoch : 3 | loss : 0.37396684722111273\n",
      "epoch : 4 | loss : 0.38722448030598794\n",
      "epoch : 5 | loss : 0.22695530112110715\n",
      "epoch : 6 | loss : 0.17251554012118347\n",
      "epoch : 7 | loss : 0.13331403512997106\n",
      "epoch : 8 | loss : 0.12419762150230883\n",
      "epoch : 9 | loss : 0.1835422975390505\n",
      "epoch : 10 | loss : 0.1136810540152952\n",
      "epoch : 11 | loss : 0.25454814779380713\n",
      "epoch : 12 | loss : 0.1500426088045957\n",
      "epoch : 13 | loss : 0.2538717197177713\n",
      "epoch : 14 | loss : 0.17345311959942364\n",
      "epoch : 15 | loss : 0.1860178290735866\n",
      "epoch : 16 | loss : 0.11274468630163408\n",
      "epoch : 17 | loss : 0.12703109990293468\n",
      "epoch : 18 | loss : 0.07740500083820431\n",
      "epoch : 19 | loss : 0.14105142513154886\n",
      "epoch : 20 | loss : 0.08710948849515414\n"
     ]
    }
   ],
   "source": [
    "## training loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for question, answer in dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(question)\n",
    "        loss = criterion(output, answer[-1])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"epoch : {epoch+1} | loss : {total_loss/len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing the model\n",
    "\n",
    "def predict(model, question, threshold=0.5):\n",
    "    model.eval()\n",
    "    numerical_question = text_to_indices(question)\n",
    "    print(numerical_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"i am dhruv panchal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 81, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"what are you doing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing the model\n",
    "\n",
    "def predict(model, question, threshold=0.5):\n",
    "    model.eval()\n",
    "    numerical_question = text_to_indices(question)\n",
    "    question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
    "    # print(question_tensor.shape)\n",
    "    pre = model(question_tensor)\n",
    "    # print(pre.shape)\n",
    "    output = torch.nn.functional.softmax(pre, dim=1)\n",
    "    # print(output.shape)\n",
    "    # print(output)\n",
    "    value, index = torch.max(output, 1)\n",
    "    # print(value)\n",
    "    # print(value.shape)\n",
    "    # print(index)\n",
    "    # print(index.shape)\n",
    "    if value < threshold:\n",
    "        print(\"sorry i dont know\")\n",
    "    else:\n",
    "        print(list(vocab.keys())[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorry i dont know\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"i am dhruv panchal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorry i dont know\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"where are you from?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"what is the capital of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"who created you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"who needs you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"you are insane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
